{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 1: Standardized Test Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 1\n",
    "\n",
    "Part 1 requires knowledge of basic Python.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide on your problem statement that will guide your analysis for this project. For guidelines, sample prompts, or inspiration, check out the README.\n",
    "\n",
    "**To-Do:** *Replace this cell with your problem statement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "- [Background](#Background)\n",
    "- [Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-Data)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amidst the covid-19 pandemic in 2019, many U.S. colleges started to implement test-optional admission process. The decision to exempt sat/act test results by some U.S. colleges has received supports and critics alike. In 2019 The pandemic reportedly hurt studentsâ€™ test results, resulting in a drastic drop in submission of test results. 2 Ivy League Schools exempted test results for admission. In 2020, More renowned colleges exempted test results from admission process, resulting in many more liberal colleges to follow suit. In 2021, Majority of the US Colleges exempted test results from admission process; Some decided for the implementation to be permanent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell (or edit the above cell) with any other background or information that is necessary for your problem statement.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your Data\n",
    "\n",
    "There are 10 datasets included in the [`data`](./data/) folder for this project. You are required to pick **at least two** of these to complete your analysis. Feel free to use more than two if you would like, or add other relevant datasets you find online.\n",
    "\n",
    "* [`sat_act_by_college.csv`](./data/sat_act_by_college.csv): Ranges of Accepted ACT & SAT Student Scores by Colleges\n",
    "* [`MERGED2013_14_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2013 to 2014\n",
    "* [`MERGED2014_15_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2014 to 2015\n",
    "* [`MERGED2015_16_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2015 to 2016\n",
    "* [`MERGED2017_18_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2016 to 2017\n",
    "* [`MERGED2018_19_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2017 to 2018\n",
    "* [`MERGED2019_20_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2018 to 2019\n",
    "* [`MERGED2020_21_PP.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2019 to 2020\n",
    "\n",
    "* [`df mean total.csv`](./data/sat_act_by_college.csv): Merged college dataset from 2013 to 2014\n",
    "* [`Minority.csv`](./data/sat_act_by_college.csv): Minority intake rate from 2018 to 2019\n",
    "* [`sat_act_submitted`](./data/sat_act_by_college.csv): sat/act submission rate 2019 vs 2020 part 1\n",
    "* [`sat_act_submitted2`](./data/sat_act_by_college.csv): sat/act submission rate 2019 vs 2020 part 2\n",
    "* [`data_scraping_us_uni.csv`](./data/sat_act_by_college.csv): Data on SAT/ graduation rate(4 years)/Graduation rate(5yrs)/     Fresh man retention rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell with the datasets you will use for your analysis. Write a brief description of the contents for each dataset that you choose.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your problem statement and your chosen datasets, spend some time doing outside research on state policies or additional information that might be relevant. Summarize your findings below. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. **Make sure that you cite your sources.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Fill out this cell with outside research or any additional background information that will support your analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding Challenges\n",
    "\n",
    "1. Manually calculate mean:\n",
    "\n",
    "    Write a function that takes in values and returns the mean of the values. Create a list of numbers that you test on your function to check to make sure your function works!\n",
    "    \n",
    "    *Note*: Do not use any mean methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n"
     ]
    }
   ],
   "source": [
    "# Code: \n",
    "def Average(num):\n",
    "    n = 0\n",
    "    for i in num:\n",
    "        n = n + i\n",
    "        \n",
    "    Avr = n/len(num)\n",
    "    return Avr\n",
    "\n",
    "print (Average([10, 11, 12, 13, 14]))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Manually calculate standard deviation:\n",
    "\n",
    "    The formula for standard deviation is below:\n",
    "\n",
    "    $$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "    Where $x_i$ represents each value in the dataset, $\\mu$ represents the mean of all values in the dataset and $n$ represents the number of values in the dataset.\n",
    "\n",
    "    Write a function that takes in values and returns the standard deviation of the values using the formula above. Hint: use the function you wrote above to calculate the mean! Use the list of numbers you created above to test on your function.\n",
    "    \n",
    "    *Note*: Do not use any standard deviation methods built-in to any Python libraries to do this! This should be done without importing any additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8944271909999159\n"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "import math \n",
    "\n",
    "def SD(num):\n",
    "   n = len(num)\n",
    "   Mean = sum(num) / n\n",
    "   x=0\n",
    "   for i in num:\n",
    "       x = x + pow((i - Mean), 2)\n",
    "       Var = x / n\n",
    "       STD = math.sqrt(Var)\n",
    "       return STD\n",
    "\n",
    "\n",
    "print(SD([11, 12, 13, 14, 15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data cleaning function:\n",
    "    \n",
    "    Write a function that takes in a string that is a number and a percent symbol (ex. '50%', '30.5%', etc.) and converts this to a float that is the decimal approximation of the percent. For example, inputting '50%' in your function should return 0.5, '30.5%' should return 0.305, etc. Make sure to test your function to make sure it works!\n",
    "\n",
    "You will use these functions later on in the project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "# Code:\n",
    "def percent2float(num):\n",
    "    x = float(num.strip('%'))/100\n",
    "    return x\n",
    "\n",
    "print (percent2float('1%'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Part 2\n",
    "\n",
    "Part 2 requires knowledge of Pandas, EDA, data cleaning, and data visualization.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.select import Select\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "delimiter = \",\"\n",
    "\n",
    "#Scrapping https://www.collegetransitions.com/dataverse/retention-and-graduation-rates\n",
    "\n",
    "with open('data_scraping_us_uni.csv', 'w') as file:\n",
    "    file.write(\"institutions, freshman_rentention_rates, gradution_rates_4_years, graduation_rates_5_years \\n\")\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "  \n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/get gd nub/Desktop/web scrapper/chromedriver.exe\", options=options)\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "url ='https://www.collegetransitions.com/dataverse/retention-and-graduation-rates#:~:text=Nationwide%2C%20the%20average%20retention%20rate,it%20takes%20to%20do%20so.'\n",
    "driver.get(url)\n",
    "\n",
    "for i in range(10):\n",
    "    institutions = driver.find_elements_by_xpath('//*[@id=\"footable_10551\"]/tbody/tr/td[1]')\n",
    "    for institution in institutions:\n",
    "        print(institution.text)\n",
    "        \n",
    "    freshman_rentention_rates = driver.find_elements_by_xpath('//*[@id=\"footable_10551\"]/tbody/tr/td[2]')\n",
    "    for freshman_rentention_rate in freshman_rentention_rates:\n",
    "        print(freshman_rentention_rate.text)\n",
    "        \n",
    "    gradution_rates_4_years = driver.find_elements_by_xpath('//*[@id=\"footable_10551\"]/tbody/tr/td[3]')\n",
    "    for gradution_rate_4_years in  gradution_rates_4_years:\n",
    "        print(gradution_rate_4_years.text)\n",
    "        \n",
    "    graduation_rates_5_years  = driver.find_elements_by_xpath('//*[@id=\"footable_10551\"]/tbody/tr/td[4]')\n",
    "    for graduation_rate_5_years in graduation_rates_5_years:\n",
    "        print(graduation_rate_5_years.text)\n",
    "        \n",
    "    with open('data_scraping_us_uni.csv', 'a') as file:\n",
    "        for i in range(len(institutions)):\n",
    "            file.write(institutions[i].text + \",\" + freshman_rentention_rates[i].text + \",\" + gradution_rates_4_years[i].text + \",\" + graduation_rates_5_years[i].text + \"\\n\")\n",
    "                       \n",
    "    try:\n",
    "                driver.find_element_by_xpath('//*[@id=\"footable_10551\"]/tfoot/tr/td/div/ul/li[15]/a').click()\n",
    "    except NoSuchElementException:\n",
    "                print(\"cmi la cb\")\n",
    "                \n",
    "                open()\n",
    "                               \n",
    "    file.close()\n",
    "    \n",
    "#Scraping https://www.insidehighered.com/admissions/article/2021/03/08/common-application-data-show-most-applicants-are-not-submitting-test\n",
    "\n",
    "with open('sat_act_submitted.csv', 'w') as file:\n",
    "    file.write(\"Category of College, Percentage Submitted Scaores 2019, Percentage Submitted Scores 2020 \\n\")\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "  \n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/get gd nub/Desktop/web scrapper/chromedriver.exe\", options=options)\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "url ='https://www.insidehighered.com/admissions/article/2021/03/08/common-application-data-show-most-applicants-are-not-submitting-test'\n",
    "driver.get(url)\n",
    "\n",
    "    col_1 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[1]/tbody/tr/td[1]')\n",
    "    for col1 in col_1:\n",
    "        print(col1.text)\n",
    "        \n",
    "    col_2 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[1]/tbody/tr/td[2]')\n",
    "    for col2 in col_2:\n",
    "        print(col2.text)\n",
    "        \n",
    "    col_3 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[1]/tbody/tr/td[3]')\n",
    "    for col3 in col_3:\n",
    "        print(col3.text)\n",
    "        \n",
    "    with open('sat_act_submitted.csv', 'a') as file:\n",
    "        for i in range(len(col_1)):\n",
    "            file.write(col_1[i].text + \",\" + col_2[i].text + \",\" + col_3[i].text + \",\" + \"\\n\")\n",
    "                       \n",
    "    file.close()\n",
    "    \n",
    "#Scraping https://www.insidehighered.com/admissions/article/2021/03/08/common-application-data-show-most-applicants-are-not-submitting-test\n",
    "\n",
    "with open('sat_act_submitted2.csv', 'w') as file:\n",
    "    file.write(\"Category of College, Percentage Submitted Scaores 2019, Percentage Submitted Scores 2020 \\n\")\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "  \n",
    "driver = webdriver.Chrome(executable_path=\"C:/Users/biyin/Desktop/web scrapper/chromedriver.exe\", options=options)\n",
    "driver.set_window_size(1120, 1000)\n",
    "\n",
    "url ='https://www.insidehighered.com/admissions/article/2021/03/08/common-application-data-show-most-applicants-are-not-submitting-test'\n",
    "driver.get(url)\n",
    "\n",
    "    col_4 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[2]/tbody/tr/td[1]')\n",
    "    for col4 in col_4:\n",
    "        print(col4.text)\n",
    "        \n",
    "    col_5 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[2]/tbody/tr/td[2]')\n",
    "    for col5 in col_5:\n",
    "        print(col5.text)\n",
    "        \n",
    "    col_6 = driver.find_elements_by_xpath('//*[@id=\"block-system-main\"]/div/div/div[2]/div[1]/div/div[15]/div/div/div/div/div/table[2]/tbody/tr/td[3]')\n",
    "    for col6 in col_6:\n",
    "        print(col6.text)\n",
    "        \n",
    "    with open('sat_act_submitted2.csv', 'a') as file:\n",
    "        for i in range(len(col_4)):\n",
    "            file.write(col_4[i].text + \",\" + col_5[i].text + \",\" + col_6[i].text + \",\" + \"\\n\")\n",
    "                       \n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#dataframe - submittion rate 2019 vs 2020\n",
    "\n",
    "df1 = pd.read_csv('sat_act_submitted2.csv')\n",
    "\n",
    "df1.drop(df1.index[7:16],0,inplace=True)\n",
    "df1.columns = [\"1\", \"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "\n",
    "mge = df1[\"1\"]+ df1[\"2\"]+ df1[\"3\"]\n",
    "df11 = df1[[\"5\", \"6\"]]\n",
    "df1 = pd.concat([mge , df11], axis = 1)\n",
    "df1.columns = [\"Category of College\", \"% Submitted Scores 2019\",\"% Submitted Scores 2020\"]\n",
    "\n",
    "df2 = pd.read_csv('sat_act_submitted.csv')  \n",
    "df = pd.concat([df1, df2], axis = 0)\n",
    "df.reset_index(level=None, drop=True, inplace=True, col_level=0, col_fill='')\n",
    "\n",
    "df['% Submitted Scores 2019'] = df['% Submitted Scores 2019'].str.rstrip('%').astype('float') / 100.0\n",
    "df['% Submitted Scores 2020'] = df['% Submitted Scores 2020'].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "Submittion_rate_mean = pd.Series.mean(df)\n",
    "Submittion_rate_mean.to_csv(\"submittion rate 2019 vs 2020.csv\")\n",
    "\n",
    "#dataframe - Collegetransition Data 2021\n",
    "\n",
    "df2021 = pd.read_csv('data_scraping_us_uni.csv')\n",
    "df2021_mean = pd.Series.mean(df2021[\" freshman_rentention_rates\"])\n",
    "df2021[' freshman_rentention_rates'] = df2021[' freshman_rentention_rates'].str.rstrip('%').astype('float') / 100.0\n",
    "df2021[' gradution_rates_4_years'] = df2021[' gradution_rates_4_years'].str.rstrip('%').astype('float') / 100.0\n",
    "df2021[' graduation_rates_5_years '] = df2021[' graduation_rates_5_years '].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "#dataframe - Collegescorecard Data 2013 to 2020\n",
    "\n",
    "df2020 = pd.read_csv('MERGED2019_20_PP.csv')\n",
    "\n",
    "df2020 = df2020[[\"INSTNM\", \"RET_FT4\", \"C150_4\", \"SAT_AVG\"]]\n",
    "df2020.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2020_merged = pd.merge(df_colleges, df2020, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2019 = pd.read_csv('MERGED2018_19_PP.csv')\n",
    "df2019 = df2019[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2019.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2019_merged = pd.merge(df_colleges, df2019, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2018 = pd.read_csv('MERGED2017_18_PP.csv')\n",
    "df2018 = df2018[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2018.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2018_merged = pd.merge(df_colleges, df2018, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2017 = pd.read_csv('MERGED2016_17_PP.csv')\n",
    "df2017 = df2017[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2017.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2017_merged = pd.merge(df_colleges, df2017, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2016 = pd.read_csv('MERGED2015_16_PP.csv')\n",
    "df2016 = df2016[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2016.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2016_merged = pd.merge(df_colleges, df2016, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2015 = pd.read_csv('MERGED2014_15_PP.csv')\n",
    "df2015 = df2015[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2015.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2015_merged = pd.merge(df_colleges, df2015, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2014 = pd.read_csv('MERGED2013_14_PP.csv')\n",
    "df2014 = df2014[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2014.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"]\n",
    "df_2014_merged = pd.merge(df_colleges, df2014, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "\n",
    "df2013 = pd.read_csv('MERGED2012_13_PP.csv')\n",
    "df2013 = df2013[[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]]\n",
    "df2013.columns = [\"institutions\", \" freshman_rentention_rates\", \" gradution_rates_4_years\", \"SAT Average\"] \n",
    "df_2013_merged = pd.merge(df_colleges, df2013, how='inner', on=\"institutions\")#drawing len(df2021) sample from all Collegescoredatas\n",
    "\n",
    "#Data Prep for Correlation analysis between SAT and Freshman Retention Rate\n",
    "\n",
    "df2018_nonan = df2018.fillna(df2018.median())\n",
    "data = df2018_nonan[[' freshman_rentention_rates','SAT Average']]\n",
    "\n",
    "#Data Prep for Correlation analysis between SAT and Graduation Rate\n",
    "\n",
    "df2020_nonan = df2020.fillna(df2020.median())\n",
    "data1 = df2020_nonan[[' gradution_rates_4_years','SAT Average']]\n",
    "\n",
    "#Data Prep for Correlation analysis between GPA and HSGPA/ GPA and SAT\n",
    "\n",
    "gpa_sat = pd.read_csv('gpa_sat.csv')\n",
    "gpa_sat_merged = pd.merge(gpa_sat, df2018, how='inner', on=\"institutions\")#drawing len(gpa_sat) sample from all Collegescoredatas\n",
    "gpa_sat_merged_nonan = gpa_sat_merged.fillna(gpa_sat_merged.median())\n",
    "\n",
    "data3 = gpa_sat_merged_nonan[['SAT Average', 'Average GPA']]\n",
    "correlation_gpa_sat = data3.corr(method='pearson')\n",
    "correlation_gpa_sat.to_csv(\"correlation_gpa_sat.csv\")\n",
    "gpa_sat_merged_nonan.to_csv(\"gpa_sat_merged_nonan.csv\")\n",
    "data4 = gpa_sat_merged_nonan[['Average GPA  of accepted students', 'Average GPA']]\n",
    "\n",
    "#Data comparing minority intake 2018 and 2019\n",
    "\n",
    "minority = pd.read_csv(\"minority.csv\")\n",
    "minority_sum = minority.sum(axis=1)\n",
    "minority_percentage = minority_sum.iloc.set_index('W').apply(pd.to_datetime).diff(-1, axis=1)\n",
    "minority_sum.to_csv(\"minority sum.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Feature                 | type  | Dataset                                                | Description                   |\n",
    "|---                      |---    |---                                                     |---                            |\n",
    "|freshman_rentention_rates| float | df 2013-2020, df mean total, df2020nonan, df2018nonan  | fresh man retention rates     |   \n",
    "|Average GPA              | float | gpa_sat gpa_sat_merged, gpa_set_nonan                  | Average College GPA           |\n",
    "|gradution_rates_4_years  | float | df 2013 -2020, df mean total, df2020nonan, df2018nonan | Graudation rate 4 years       |\n",
    "|SAT average              | float | gpa_sat gpa_sat_merged, gpa_set_nonan                  | Average SAT score             |\n",
    "|% submitted score 2019   | float | df                                                     |% of SAT/ACT scores submitted  |\n",
    "|% submitted score 2020   | float | df                                                     |% of SAT/ACT scores submitted  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit the table below to create your own data dictionary for the datasets you chose.*\n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|column name|int/float/object|ACT/SAT|This is an example| \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Complete the following steps to explore your data. You are welcome to do more EDA than the steps outlined here as you feel necessary:\n",
    "1. Summary Statistics.\n",
    "2. Use a **dictionary comprehension** to apply the standard deviation function you create in part 1 to each numeric column in the dataframe.  **No loops**.\n",
    "    - Assign the output to variable `sd` as a dictionary where: \n",
    "        - Each column name is now a key \n",
    "        - That standard deviation of the column is the value \n",
    "        - *Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`\n",
    "3. Investigate trends in the data.\n",
    "    - Using sorting and/or masking (along with the `.head()` method to avoid printing our entire dataframe), consider questions relevant to your problem statement. Some examples are provided below (but feel free to change these questions for your specific problem):\n",
    "        - Which states have the highest and lowest participation rates for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Which states have the highest and lowest mean total/composite scores for the 2017, 2019, or 2019 SAT and ACT?\n",
    "        - Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "        - Do any states show have >50% participation on *both* tests each year?\n",
    "        - Which colleges have the highest median SAT and ACT scores for admittance?\n",
    "        - Which California school districts have the highest and lowest mean test scores?\n",
    "    - **You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:\n",
    "#Mean of [[\"INSTNM\", \"C150_4\", \"RET_FT4\", \"SAT_AVG\"]] Throughout the years\n",
    "df2021_mean = pd.Series.mean(df2021)\n",
    "df2020_mean = pd.Series.mean(df_2020_merged)\n",
    "df2019_mean = pd.Series.mean(df_2019_merged)\n",
    "df2018_mean = pd.Series.mean(df_2018_merged)\n",
    "df2017_mean = pd.Series.mean(df_2017_merged)\n",
    "df2016_mean = pd.Series.mean(df_2016_merged)\n",
    "df2015_mean = pd.Series.mean(df_2015_merged)\n",
    "df2014_mean = pd.Series.mean(df_2014_merged)\n",
    "df2013_mean = pd.Series.mean(df_2013_merged)\n",
    "\n",
    "df_mean_total = pd.concat([df2013_mean, df2014_mean, df2015_mean, df2016_mean, df2017_mean, df2018_mean, df2019_mean, df2020_mean, df2021_mean], axis = 1)\n",
    "df_mean_total.columns = [\"2013\", \"2014\",\"2015\",\"2016\",\"2017\",\"2018\", \"2019\", \"2020\", \"2021\" ]\n",
    "df_mean_total = df_mean_total.transpose()\n",
    "del df_mean_total[\"graduation_rates_5_years \"]\n",
    "del df_mean_total[\"SAT Average\"]\n",
    "df_mean_total.reset_index(inplace = True)\n",
    "df_mean_total.columns = [\"years\", \"freshman_rentention_rates\", \"gradution_rates_4_years\"]\n",
    "#A sharp drop in grdaution rate and a sharp increase in freshman retention rate upon exemption of sat/act test in 2019\n",
    "\n",
    "\n",
    "#Mean of Submittion rate 2019 vs 2020\n",
    "Submittion_rate_mean = pd.Series.mean(df)\n",
    "Submittion_rate_mean.to_csv(\"submittion rate 2019 vs 2020.csv\")\n",
    "#findings: 37% less people submmited sat/act scores upon the exemption in 2019 as compared to 2020\n",
    "\n",
    "\n",
    "#correlation coefficient test - SAT/GRADUATION RATE\n",
    "correlation = data1.corr(method='pearson')\n",
    "#finding: sat has a midieum correlation of 0.51 with graduation rate (4 yrs)\n",
    "\n",
    "\n",
    "#correlation coefficient test - SAT/FRESHMAN RETENTION RATE\n",
    "correlation_sat_retention = data.corr(method='pearson')\n",
    "#finding: sat has a midieum correlation of 0.5 with freshman retention rates\n",
    "\n",
    "\n",
    "#correlation between College GPA with HSGPA and SAT\n",
    "gpa_sat = pd.read_csv('gpa_sat.csv')\n",
    "gpa_sat_merged = pd.merge(gpa_sat, df2018, how='inner', on=\"institutions\")#drawing len(gpa_sat) sample from all Collegescoredatas\n",
    "gpa_sat_merged_nonan = gpa_sat_merged.fillna(gpa_sat_merged.median())\n",
    "\n",
    "data3 = gpa_sat_merged_nonan[['SAT Average', 'Average GPA']]\n",
    "correlation_gpa_sat = data3.corr(method='pearson')\n",
    "correlation_gpa_sat.to_csv(\"correlation_gpa_sat.csv\")\n",
    "gpa_sat_merged_nonan.to_csv(\"gpa_sat_merged_nonan.csv\")\n",
    "\n",
    "data4 = gpa_sat_merged_nonan[['Average GPA  of accepted students', 'Average GPA']]\n",
    "correlation_gpa_hsgpa = data4.corr(method='pearson')\n",
    "#finding: College gpa has a higher correlation with HSGPA (0.83) then with SAT (0.78)\n",
    "\n",
    "#Comparing percentages of minority admission rate 2018 vs 2019\n",
    "minority_sum = minority.sum(axis=1)\n",
    "minority_percentage = minority_sum.iloc.set_index('W').apply(pd.to_datetime).diff(-1, axis=1)\n",
    "#findings: 9.7% increase in admission of minority in US colleges in 2019 from 2018\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To-Do:** *Edit this cell with your findings on trends in the data (step 3 above).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers. It is important to not only create visualizations, but to **interpret your visualizations** as well.\n",
    "\n",
    "**Every plot should**:\n",
    "- Have a title\n",
    "- Have axis labels\n",
    "- Have appropriate tick labels\n",
    "- Text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Have an interpretation to aid understanding\n",
    "\n",
    "Here is an example of what your plots should look like following the above guidelines. Note that while the content of this example is unrelated, the principles of visualization hold:\n",
    "\n",
    "![](https://snag.gy/hCBR1U.jpg)\n",
    "*Interpretation: The above image shows that as we increase our spending on advertising, our sales numbers also tend to increase. There is a positive correlation between advertising spending and sales.*\n",
    "\n",
    "---\n",
    "\n",
    "Here are some prompts to get you started with visualizations. Feel free to add additional visualizations as you see fit:\n",
    "1. Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features.\n",
    "    - Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "    - Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative).\n",
    "2. Visualize distributions using histograms. If you have a lot, consider writing a custom function and use subplots.\n",
    "    - *OPTIONAL*: Summarize the underlying distributions of your features (in words & statistics)\n",
    "         - Be thorough in your verbal description of these distributions.\n",
    "         - Be sure to back up these summaries with statistics.\n",
    "         - We generally assume that data we sample from a population will be normally distributed. Do we observe this trend? Explain your answers for each distribution and how you think this will affect estimates made from these data.\n",
    "3. Plot and interpret boxplots. \n",
    "    - Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "    - Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "    - Each boxplot should:\n",
    "        - Only include variables of a similar scale\n",
    "        - Have clear labels for each variable\n",
    "        - Have appropriate titles and labels\n",
    "4. Plot and interpret scatter plots to view relationships between features. Feel free to write a custom function, and subplot if you'd like. Functions save both time and space.\n",
    "    - Your plots should have:\n",
    "        - Two clearly labeled axes\n",
    "        - A proper title\n",
    "        - Colors and symbols that are clear and unmistakable\n",
    "5. Additional plots of your choosing.\n",
    "    - Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "#trend graduation rates and retention rate\n",
    "df_mean_total.to_csv(\"df mean total.csv\")\n",
    "\n",
    "x1 = df_mean_total['years']\n",
    "y1 = df_mean_total['freshman_rentention_rates']\n",
    "plt.plot(x1, y1, label = \"Freshman Retention Rates\")\n",
    "\n",
    "x2 = df_mean_total['years']\n",
    "y2 = df_mean_total['gradution_rates_4_years']\n",
    "plt.plot(x2, y2, label = \"Graduation Rates 4 Years\")\n",
    "\n",
    "plt.xlabel('x - axis')\n",
    "plt.ylabel('y - axis')\n",
    "plt.title('Trends')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#correlation between graduation rate and SAT\n",
    "x3 = df2020_nonan[' gradution_rates_4_years']\n",
    "y3 = df2020_nonan['SAT Average']\n",
    "plt.scatter(x3, y3)\n",
    "plt.show()\n",
    "\n",
    "#correlation between retention rate and sat\n",
    "x4 = df2020_nonan[' freshman_rentention_rates']\n",
    "y4 = df2020_nonan['SAT Average']\n",
    "plt.scatter(x4, y4)\n",
    "plt.show()\n",
    "\n",
    "#correlation between College GPA vs SAT\n",
    "x6 = gpa_sat_merged_nonan['Average GPA']\n",
    "y6 = gpa_sat_merged_nonan['SAT Average']\n",
    "plt.scatter(x6, y6)\n",
    "plt.show()\n",
    "\n",
    "#correlation between College GPA vs HSGPA\n",
    "x7 = gpa_sat_merged_nonan['Average GPA']\n",
    "y7 = gpa_sat_merged_nonan['Average GPA  of accepted students']\n",
    "plt.scatter(x7, y7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Make sure to answer your question of interest or address your problem statement here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "carry on exemption of SAT*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to create your README!\n",
    "\n",
    "**To-Do:** *If you combine your problem statement, data dictionary, brief summary of your analysis, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.* Don't forget to cite your data sources!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
